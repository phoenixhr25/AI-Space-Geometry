# Week 1 Â· æ¢¯åº¦çš„å±±è°· (The Valley of Gradient)

> ğŸ“… 2025.12.02 â€“ 12.08  
> ğŸ¯ æ¦‚å¿µï¼šå­¦ä¹ æ˜¯æ²¿ç€èƒ½é‡é¢ä¸‹æ»‘çš„è¿‡ç¨‹ï¼ˆLearning as Gradient Descentï¼‰

---

ğŸ§® æ•°å­¦æ ¸å¿ƒ  
ç¥ç»ç½‘ç»œçš„è®­ç»ƒï¼Œå°±åƒåœ¨ä¸€å¼ èµ·ä¼çš„èƒ½é‡åœ°å½¢å›¾ä¸Šâ€œä¸‹å±±â€ã€‚  
æ¨¡å‹å‚æ•° Î¸ çš„æ¯ä¸€æ¬¡æ›´æ–°ï¼Œéƒ½æ˜¯åœ¨èƒ½é‡é¢ä¸Šæ²¿æ¢¯åº¦æ–¹å‘ä¸‹é™ï¼š

![Gradient descent](https://latex.codecogs.com/svg.image?\theta_{t+1}=\theta_t-\eta\nabla_{\theta}L(\theta_t))

å…¶ä¸­ï¼š  
- L(Î¸)ï¼šæŸå¤±å‡½æ•°ï¼ˆèƒ½é‡ï¼‰  
- âˆ‡â‚Î¸â‚ Lï¼šæ¢¯åº¦ï¼ˆå¡åº¦æ–¹å‘ï¼‰  
- Î·ï¼šå­¦ä¹ ç‡ï¼ˆæ­¥é•¿ï¼‰

---

## ğŸ§­ å‡ ä½•ç›´è§‰

- é«˜èƒ½é‡ç‚¹ï¼šæ¨¡å‹é¢„æµ‹é”™è¯¯å¤šã€Loss é«˜ã€‚  
- ä½èƒ½é‡è°·ï¼šæ¨¡å‹é€¼è¿‘çœŸå®åˆ†å¸ƒã€‚  
- å±€éƒ¨æå°å€¼ï¼šæš‚æ—¶ç¨³å®šä½†éæœ€ä¼˜ã€‚  

å­¦ä¹ çš„ç›®æ ‡æ˜¯æ‰¾åˆ°â€œæœ€æ·±çš„è°·åº•â€ï¼Œ  
ä¹Ÿå°±æ˜¯åœ¨ä¿¡æ¯ç©ºé—´ä¸­æœ€å°åŒ–æŸå¤±çš„ç‚¹ã€‚

---

## ğŸ“Š Python ç¤ºä¾‹ï¼šäºŒç»´èƒ½é‡é¢

```python
import numpy as np
import matplotlib.pyplot as plt

# æ„é€ èƒ½é‡å‡½æ•°
def loss_surface(x, y):
    return (x**2 + y**2) + 0.5*np.sin(3*x)*np.cos(3*y)

# ç½‘æ ¼
x = np.linspace(-3, 3, 200)
y = np.linspace(-3, 3, 200)
X, Y = np.meshgrid(x, y)
Z = loss_surface(X, Y)

plt.figure(figsize=(6,5))
cp = plt.contourf(X, Y, Z, levels=40)
plt.colorbar(cp)
plt.title("Loss Surface Landscape")
plt.xlabel("Parameter x")
plt.ylabel("Parameter y")
plt.show()
